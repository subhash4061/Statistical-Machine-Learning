{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Part 1: Density Estimation and Classification using Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=scipy.io.loadmat(\"fashion_mnist.mat\")\n",
    "#print(data)\n",
    "trainX=data['trX']\n",
    "trainY=np.reshape(data['trY'],-1)\n",
    "testX=data['tsX']\n",
    "testY=np.reshape(data['tsY'],-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACTING THE FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "fet1=np.mean(trainX,axis=1)\n",
    "fet2=np.std(trainX,axis=1)\n",
    "trainX=pd.DataFrame({'trainF1': fet1, 'trainF2': fet2})\n",
    "fett1=np.mean(testX,axis=1)\n",
    "fett2=np.std(testX,axis=1)\n",
    "testX=pd.DataFrame({'testF1': fett1,'testF2':fett2})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESTIMATION OF PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior of class 0: 0.5\n",
      "mean of class 0 : trainF1    0.325608\n",
      "trainF2    0.320036\n",
      "dtype: float64\n",
      "std of class 0  : trainF1    0.113375\n",
      "trainF2    0.087983\n",
      "dtype: float64\n",
      "prior of class 1: 0.5\n",
      "mean of class 1 : trainF1    0.222905\n",
      "trainF2    0.333942\n",
      "dtype: float64\n",
      "std of class 1  : trainF1    0.056951\n",
      "trainF2    0.057032\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def estimate_parameters(trainX,trainY):\n",
    "    '''\n",
    "    This function estimate the parameters for naive bayes..\n",
    "    '''\n",
    "    tshirt=trainX[trainY==0]\n",
    "    trouser=trainX[trainY==1]\n",
    "    paras={}\n",
    "    paras['y_0']=0.5\n",
    "    paras['mu_tsh']=np.mean(tshirt,axis=0)\n",
    "    paras['std_tsh']=np.std(tshirt,axis=0)\n",
    "    paras['y_1']=0.5\n",
    "    paras['mu_tro']=np.mean(trouser,axis=0)\n",
    "    paras['std_tro']=np.std(trouser,axis=0)\n",
    "    print('prior of class 0:',paras['y_0'])\n",
    "    print('mean of class 0 :',paras['mu_tsh'])\n",
    "    print('std of class 0  :',paras['std_tsh'])\n",
    "    print('prior of class 1:',paras['y_1'])\n",
    "    print('mean of class 1 :',paras['mu_tro'])\n",
    "    print('std of class 1  :',paras['std_tro'])\n",
    "    return paras\n",
    "paras = estimate_parameters(trainX,trainY)\n",
    "#y_0 is prior of Tshirt class\n",
    "#mu_tsh is mean of the Tshirt class\n",
    "#std_tsh is standard deviation of the Tshirt class\n",
    "#y_1 is prior of Trouser class\n",
    "#mu_tro is mean of the Trouser class\n",
    "#std_tro is standard deviation of the Trouser class\n",
    "#trainF1 is the feature 1 in training data set\n",
    "#trainF2 is the feature 2 in training data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAIVE BAYES CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAIVE BAYES RESULTS\n",
      "Class Tshirt accuracy : 78.40 %\n",
      "Class Trouser accuracy: 87.90 %\n",
      "Overall accuracy      : 83.15 %\n"
     ]
    }
   ],
   "source": [
    "pred=[]\n",
    "def naive_bayes(testX,paras):\n",
    "    '''\n",
    "    It uses parameters and predicts the class of the given test set....\n",
    "    '''\n",
    "    for x in testX.to_numpy():\n",
    "        denom = np.sqrt(2*np.pi*(paras[\"std_tro\"]**2))\n",
    "        numer = np.exp(-np.square(x - paras[\"mu_tro\"]) / (2*(paras[\"std_tro\"]**2)))\n",
    "        p_tro = np.sum(np.log(numer/denom))\n",
    "        denom = np.sqrt(2*np.pi*(paras[\"std_tsh\"]**2))\n",
    "        numer = np.exp(-np.square(x - paras[\"mu_tsh\"]) / (2*(paras[\"std_tsh\"]**2)))\n",
    "        p_tsh = np.sum(np.log(numer/denom))\n",
    "        if p_tro>p_tsh:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(0)\n",
    "\n",
    "    acc = np.sum(pred == testY) / len(testY)\n",
    "    count=count1=0\n",
    "    for i in range(len(testY)):\n",
    "        if pred[i]==testY[i]:\n",
    "            if pred[i]==0:\n",
    "                count=count+1\n",
    "            else:\n",
    "                count1=count1+1\n",
    "    acc_tsh=count*2/len(testY)\n",
    "    acc_tro=count1*2/len(testY)\n",
    "    print('NAIVE BAYES RESULTS')\n",
    "    print('Class Tshirt accuracy :',\"%.2f\" % (acc_tsh*100),'%')\n",
    "    print('Class Trouser accuracy:',\"%.2f\" % (acc_tro*100),'%')\n",
    "    print('Overall accuracy      :',\"%.2f\" % (acc*100),'%')\n",
    "naive_bayes(testX,paras)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weights obtained from gradient ascent: [-177.69004367] [189.13702829]\n",
      "The bias value: -14.804176432569857\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    '''\n",
    "    This calculates the sigmoid of the given input...\n",
    "    '''\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def log_likelihood(y_pred, y):\n",
    "    '''\n",
    "    This function calculates the log likelihood using actual and predicted value...\n",
    "    '''\n",
    "    eps = 1e-7\n",
    "    y_pred = np.maximum(np.full(y_pred.shape, eps), np.minimum(np.full(y_pred.shape, 1-eps), y_pred))\n",
    "        \n",
    "    return np.sum(y*np.log(y_pred)+(1-y)*np.log(1-y_pred))\n",
    "\n",
    "def logistic_regression_train(trainX, trainY, epoches,learning_rate):\n",
    "    '''\n",
    "    This function learns the parameters from the training set with gradient ascent....\n",
    "    '''\n",
    "    \n",
    "    trainX= trainX.T\n",
    "    trainY = trainY.T\n",
    "    m = trainX.shape[1]\n",
    "    n = trainX.shape[0]\n",
    "    w = np.zeros((n,1))\n",
    "    w_0 = 0\n",
    "    for i in range(epoches):\n",
    "        z = np.dot(w.T,trainX)+w_0\n",
    "        tes = sigmoid(z)\n",
    "        log_likelihood(tes, trainY)\n",
    "        diff = trainY - tes\n",
    "        dw_0 = np.sum(diff)\n",
    "        dw = np.dot(trainX, diff.T)\n",
    "        w = w + learning_rate * dw\n",
    "        w_0 = w_0 + learning_rate * dw_0\n",
    "    print('The weights obtained from gradient ascent:',w[0],w[1])\n",
    "    print('The bias value:',w_0)\n",
    "    return [w, w_0]\n",
    "\n",
    "params = logistic_regression_train(trainX, trainY, 500,0.01) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION RESULTS\n",
      "Class Tshirt accuracy : 92.50 %\n",
      "Class Trouser accuracy: 91.70 %\n",
      "Overall accuracy      : 92.10 %\n"
     ]
    }
   ],
   "source": [
    "def logistic_regression_predict( testX, testY, paras):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    testX = testX.T\n",
    "    testY = testY.T \n",
    "    m = testX.shape[1]\n",
    "    n = testX.shape[0]\n",
    "    w = params[0]\n",
    "    w_0 = params[1]\n",
    "    z = np.dot(w.T,testX) + w_0\n",
    "    tes = sigmoid(z)\n",
    "    y_pred = (tes > 0.5) * 1.0\n",
    "    accuracy = np.sum(testY == y_pred) / float(m)\n",
    "    count=count1=0\n",
    "#     print(y_pred)\n",
    "    y_pred=y_pred.T\n",
    "#     print(testY)\n",
    "    \n",
    "    for i in range(len(testY)):\n",
    "        if y_pred[i]==testY[i]:\n",
    "            if y_pred[i]==0:\n",
    "                count=count+1\n",
    "            else:\n",
    "                count1=count1+1\n",
    "    acc_tsh=count*2/len(testY)\n",
    "    acc_tro=count1*2/len(testY)\n",
    "    print('LOGISTIC REGRESSION RESULTS')\n",
    "    print('Class Tshirt accuracy :',\"%.2f\" % (acc_tsh*100),'%')\n",
    "    print('Class Trouser accuracy:',\"%.2f\" % (acc_tro*100),'%')\n",
    "    print('Overall accuracy      :',\"%.2f\" % (accuracy*100),'%')\n",
    "logistic_regression_predict(testX,testY,paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
